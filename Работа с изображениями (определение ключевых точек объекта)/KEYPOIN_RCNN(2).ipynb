{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ссылка на данные:\n",
        "\n",
        "https://drive.google.com/drive/folders/1lcxpKkBuAXYJlagiTc0GkD5EDajS-J_V"
      ],
      "metadata": {
        "id": "k88VhsHnSUEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import KeypointRCNN\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# load a pre-trained model for classification and return\n",
        "# only the features\n",
        "backbone = torchvision.models.mobilenet_v3_small(weights=torchvision.models.MobileNet_V3_Small_Weights.DEFAULT).features\n",
        "# KeypointRCNN needs to know the number of\n",
        "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
        "# so we need to add it here\n",
        "backbone.out_channels = 576\n",
        "\n",
        "# let's make the RPN generate 5 x 3 anchors per spatial\n",
        "# location, with 5 different sizes and 3 different aspect\n",
        "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
        "# map could potentially have different sizes and\n",
        "# aspect ratios\n",
        "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
        "                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
        "\n",
        "# let's define what are the feature maps that we will\n",
        " # use to perform the region of interest cropping, as well as\n",
        "# the size of the crop after rescaling.\n",
        "# if your backbone returns a Tensor, featmap_names is expected to\n",
        "# be ['0']. More generally, the backbone should return an\n",
        "# OrderedDict[Tensor], and in featmap_names you can choose which\n",
        "# feature maps to use.\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                output_size=7,\n",
        "                                                sampling_ratio=2)\n",
        "keypoint_roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
        "                                                         output_size=14,\n",
        "                                                         sampling_ratio=2)\n",
        "# put the pieces together inside a KeypointRCNN model\n",
        "model = KeypointRCNN(backbone,\n",
        "                     num_classes=2,\n",
        "                     rpn_anchor_generator=anchor_generator,\n",
        "                     box_roi_pool=roi_pooler,\n",
        "                     keypoint_roi_pool=keypoint_roi_pooler, num_keypoints=30)\n",
        "model.eval()\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        "x = [torch.rand(3, 300, 400).to(DEVICE), torch.rand(3, 500, 400).to(DEVICE)]\n",
        "predictions = model(x)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Po-ZL4R7QfLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import KeypointRCNN\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "keypointrcnn_resnet50_fpn(pretrained=False, num_keypoints=30)\n",
        "model.eval()\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        "x = [torch.rand(3, 300, 400).to(DEVICE), torch.rand(3, 500, 400).to(DEVICE)]\n",
        "predictions = model(x)\n",
        "predictions"
      ],
      "metadata": {
        "id": "j1peyTPgt0la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "id=\"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "BzBMp7khZKV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c4258e-222b-4a16-99b8-c8d687d6705b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import json\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "class ClassDataset(Dataset):\n",
        "    def __init__(self, annotation, image_dir):                \n",
        "        self.images=[]\n",
        "        self.count=0\n",
        "        self.targets = []\n",
        "        self.imgs_files=[]\n",
        "        annotation=pd.read_csv(annotation)\n",
        "        annotation=annotation.to_numpy()\n",
        "        for i in range(len(annotation)):\n",
        "          target={}\n",
        "          if \"cow\" in annotation[i][0]:\n",
        "            img=cv2.imread(image_dir+\"/\"+annotation[i][0])\n",
        "            self.imgs_files.append(image_dir+\"/\"+annotation[i][0])\n",
        "          else:\n",
        "            img=cv2.imread(image_dir+\"/\"+annotation[i][0].capitalize())\n",
        "            self.imgs_files.append(image_dir+\"/\"+annotation[i][0].capitalize())\n",
        "\n",
        "          print(image_dir+\"/\"+annotation[i][0].capitalize())\n",
        "          h, w = img.shape[:2]\n",
        "          size=224\n",
        "          img = cv2.resize(img, (size, size))\n",
        "          F = transforms.ToTensor()\n",
        "          keypoints=[]\n",
        "          x_min=1.0\n",
        "          y_min=1.0\n",
        "          x_max=0.0\n",
        "          y_max=0.0\n",
        "          for j in range(1, len(annotation[i])):\n",
        "            if j%3==2:\n",
        "              k=[]\n",
        "              k.append(annotation[i][j]/w)\n",
        "              x_min=min(x_min, annotation[i][j]/w)\n",
        "              x_max=max(x_max, annotation[i][j]/w)\n",
        "            if j%3==0:\n",
        "              k.append(annotation[i][j]/h)\n",
        "              y_min=min(y_min,annotation[i][j]/h)\n",
        "              y_max=max(y_max,annotation[i][j]/h)\n",
        "\n",
        "              k.append(annotation[i][j-2])\n",
        "              keypoints.append(k)\n",
        "          bboxes=torch.Tensor([[x_min,y_min,x_max,y_max]])\n",
        "          target[\"boxes\"] = bboxes\n",
        "          target[\"labels\"] = torch.as_tensor([1 for _ in bboxes], dtype=torch.int64)\n",
        "          target[\"image_id\"] = torch.tensor([i])\n",
        "          target[\"area\"] = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
        "          target[\"iscrowd\"] = torch.zeros(len(bboxes), dtype=torch.int64)\n",
        "          target[\"keypoints\"] = torch.as_tensor([keypoints], dtype=torch.float32) \n",
        "          keys=target.keys()\n",
        "          for key in keys:\n",
        "            target[key]     \n",
        "          img = F(img)\n",
        "          img\n",
        "          self.images.append(img)\n",
        "          self.targets.append(target)\n",
        "          self.count+=1\n",
        "          if self.count==200:\n",
        "            break\n",
        "        #F = transforms.ToTensor()\n",
        "         \n",
        "        # self.target[\"boxes\"] = bboxes\n",
        "        # self.target[\"labels\"] = torch.as_tensor([1 for _ in bboxes], dtype=torch.int64) # all objects are glue tubes\n",
        "        # self.target[\"image_id\"] = torch.tensor([idx])\n",
        "        # self.target[\"area\"] = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
        "        # self.target[\"iscrowd\"] = torch.zeros(len(bboxes), dtype=torch.int64)\n",
        "        # self.target[\"keypoints\"] = torch.as_tensor(keypoints, dtype=torch.float32)        \n",
        "        # self.img = F.ToTensor(img)\n",
        "        \n",
        "  \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "            return self.images[idx], self.targets[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.count\n",
        "    def get_image_files(self):\n",
        "      return self.imgs_files"
      ],
      "metadata": {
        "id": "Z81hM0CXdx6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vj2lp4ihAN2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zmq.constants import NULL\n",
        "annotation=pd.read_csv(id+\"training/data_set9/test_data1.csv\")\n",
        "\n",
        "print(annotation)\n",
        "annotation=annotation.to_numpy()\n",
        "data=[]\n",
        "for i in range(len(annotation)):\n",
        "  #line=line.remove('\"')\n",
        "  line=annotation[i][0].split(\";\")\n",
        "\n",
        "  data.append(line)\n",
        "data=pd.DataFrame(data)\n",
        "for i in range(1, 91):\n",
        "  if i%3==1:\n",
        "    data[i] = data[i].astype (int)\n",
        "  else:\n",
        "    data[i] = data[i].astype (float)\n",
        "data=data.drop(columns=[91])\n",
        "data.to_csv(\"test_dataset.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "TyHRkx46VuhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e760bc79-4956-4f68-e4ae-644a840dadd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    german+shepherd_10032.jpg;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;742.2907488986784;260.4669603524229;1;194.27312775330395;240.2026431718062;0;0;0;0;0;0;0;0;0;\n",
            "0    lion_10504.jpg;1;667.018018018018;538.35135135...                                                                                                                                                                                                                             \n",
            "1    collie_10630.jpg;1;617.0616740088105;310.63876...                                                                                                                                                                                                                             \n",
            "2    cow_10271.jpg;1;432.44827586206895;794.8275862...                                                                                                                                                                                                                             \n",
            "3    chihuahua_10272.jpg;1;737.1818181818181;293.0;...                                                                                                                                                                                                                             \n",
            "4    leopard_10089.jpg;1;619.9090909090909;727.8181...                                                                                                                                                                                                                             \n",
            "..                                                 ...                                                                                                                                                                                                                             \n",
            "596  lion_10147.jpg;1;504.40540540540536;439.900900...                                                                                                                                                                                                                             \n",
            "597  wolf_10307.jpg;1;522.6436781609195;708.6206896...                                                                                                                                                                                                                             \n",
            "598  polar+bear_10746.jpg;1;448.6363636363636;432.1...                                                                                                                                                                                                                             \n",
            "599  sheep_10859.jpg;1;307.77777777777777;406.55555...                                                                                                                                                                                                                             \n",
            "600  tiger_10004.jpg;1;431.30088495575217;524.51327...                                                                                                                                                                                                                             \n",
            "\n",
            "[601 rows x 1 columns]\n",
            "                    0   1           2           3   4           5   \\\n",
            "0       lion_10504.jpg   1  667.018018  538.351351   0    0.000000   \n",
            "1     collie_10630.jpg   1  617.061674  310.638767   1  275.651982   \n",
            "2        cow_10271.jpg   1  432.448276  794.827586   0    0.000000   \n",
            "3  chihuahua_10272.jpg   1  737.181818  293.000000   0    0.000000   \n",
            "4    leopard_10089.jpg   1  619.909091  727.818182   0    0.000000   \n",
            "\n",
            "           6   7           8         9   ...          81  82          83  \\\n",
            "0    0.000000   0    0.000000   0.00000  ...    0.000000   0    0.000000   \n",
            "1  430.022026   1  123.669604  86.85022  ...  193.458150   1  539.088106   \n",
            "2    0.000000   0    0.000000   0.00000  ...    0.000000   1  156.011494   \n",
            "3    0.000000   0    0.000000   0.00000  ...  198.454545   1  671.272727   \n",
            "4    0.000000   0    0.000000   0.00000  ...  234.181818   1  200.363636   \n",
            "\n",
            "           84  85          86          87  88   89   90  \n",
            "0    0.000000   0    0.000000    0.000000   0  0.0  0.0  \n",
            "1   77.158590   1  755.828194  538.392070   0  0.0  0.0  \n",
            "2  422.988506   0    0.000000    0.000000   0  0.0  0.0  \n",
            "3   33.454545   1  679.454545  478.909091   0  0.0  0.0  \n",
            "4  118.727273   0    0.000000    0.000000   0  0.0  0.0  \n",
            "\n",
            "[5 rows x 91 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = ClassDataset(id+\"training/dataset/train_dataset.csv\", id+\"training/animals\")\n",
        "# dataset_test = ClassDataset(KEYPOINTS_FOLDER_TEST, transform=None, demo=False)\n",
        "data_loader_train = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
        "# data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "12e0RUyUdW_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_train = DataLoader(dataset_train, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "_JJwbXh_81gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = ClassDataset(id+\"training/dataset/test_dataset.csv\", id+\"training/animals\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-jP40HF9tUQ",
        "outputId": "b7396081-c5a2-4c60-8a15-025bbfdd15b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/training/animals/Lion_10504.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10630.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10271.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10272.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10089.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10079.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10133.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10318.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10553.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10102.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10044.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10226.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10309.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10221.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10113.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10248.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10343.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10221.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10516.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10428.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10313.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10365.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10323.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10058.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_10386.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10411.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_10482.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10320.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_11026.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10112.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10217.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10059.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10427.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10830.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10123.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10033.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10352.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10656.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10447.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10126.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10114.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10033.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10105.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10528.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10088.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10278.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10041.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10318.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10503.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_11560.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10391.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10200.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10338.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10437.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10097.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10170.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10443.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10182.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10182.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_11147.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10207.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10303.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10058.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10298.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10210.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10151.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10401.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10364.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10484.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_10175.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10050.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10125.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10046.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10560.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10262.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10430.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10034.jpg\n",
            "/content/drive/MyDrive/training/animals/Buffalo_10335.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10397.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10043.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10097.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10107.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10237.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10009.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10756.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10966.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10176.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10646.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10731.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10396.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10049.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10746.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10116.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10516.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_11195.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10421.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10045.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10078.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10668.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10124.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10028.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10572.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10497.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10272.jpg\n",
            "/content/drive/MyDrive/training/animals/Lion_10434.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10039.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10259.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10366.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10336.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10295.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10701.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10867.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_11340.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10941.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_11601.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10517.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10428.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10684.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10728.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10277.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10207.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10226.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10532.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10195.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10045.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10237.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10071.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10028.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10089.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10100.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10191.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10574.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10050.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_11051.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10443.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10266.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10248.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10358.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10395.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10034.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10412.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10324.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10221.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10320.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10406.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_11026.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10339.jpg\n",
            "/content/drive/MyDrive/training/animals/Antelope_10399.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10529.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10411.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10469.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_11459.jpg\n",
            "/content/drive/MyDrive/training/animals/Ox_10513.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10055.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10471.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10420.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10540.jpg\n",
            "/content/drive/MyDrive/training/animals/Polar+bear_10790.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10668.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10472.jpg\n",
            "/content/drive/MyDrive/training/animals/Wolf_10286.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10574.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10441.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10616.jpg\n",
            "/content/drive/MyDrive/training/animals/Moose_10165.jpg\n",
            "/content/drive/MyDrive/training/animals/Leopard_10079.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10066.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10118.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10218.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10248.jpg\n",
            "/content/drive/MyDrive/training/animals/Fox_10510.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10249.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10610.jpg\n",
            "/content/drive/MyDrive/training/animals/Zebra_10357.jpg\n",
            "/content/drive/MyDrive/training/animals/Grizzly+bear_10147.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10715.jpg\n",
            "/content/drive/MyDrive/training/animals/Horse_10120.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10935.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10580.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10161.jpg\n",
            "/content/drive/MyDrive/training/animals/Buffalo_10375.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10445.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10270.jpg\n",
            "/content/drive/MyDrive/training/animals/Deer_10330.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_10848.jpg\n",
            "/content/drive/MyDrive/training/animals/Giant+panda_10676.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10399.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10180.jpg\n",
            "/content/drive/MyDrive/training/animals/German+shepherd_10038.jpg\n",
            "/content/drive/MyDrive/training/animals/Siamese+cat_10062.jpg\n",
            "/content/drive/MyDrive/training/animals/Cow_11319.jpg\n",
            "/content/drive/MyDrive/training/animals/Collie_10203.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10596.jpg\n",
            "/content/drive/MyDrive/training/animals/Persian+cat_10447.jpg\n",
            "/content/drive/MyDrive/training/animals/Chihuahua_10460.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10028.jpg\n",
            "/content/drive/MyDrive/training/animals/Tiger_10409.jpg\n",
            "/content/drive/MyDrive/training/animals/Bobcat_10141.jpg\n",
            "/content/drive/MyDrive/training/animals/Dalmatian_10546.jpg\n",
            "/content/drive/MyDrive/training/animals/Sheep_10424.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "sPw-cfyA-Dhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/drive/1YtJrw6oQQbTfTm3uwir7yXMHrLO0NmFp?hl=ru#scrollTo=IFhO39WYbZ9A\n",
        "#https://medium.com/@alexppppp/how-to-train-a-custom-keypoint-detection-model-with-pytorch-d9af90e111da"
      ],
      "metadata": {
        "id": "vUy-8x3zdcTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import datetime\n",
        "import errno\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        if not is_dist_avail_and_initialized():\n",
        "            return\n",
        "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n",
        "        dist.barrier()\n",
        "        dist.all_reduce(t)\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def all_gather(data):\n",
        "    \"\"\"\n",
        "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
        "    Args:\n",
        "        data: any picklable object\n",
        "    Returns:\n",
        "        list[data]: list of data gathered from each rank\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size == 1:\n",
        "        return [data]\n",
        "    data_list = [None] * world_size\n",
        "    dist.all_gather_object(data_list, data)\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.inference_mode():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST:\n",
        "            raise\n",
        "\n",
        "\n",
        "def setup_for_distributed(is_master):\n",
        "    \"\"\"\n",
        "    This function disables printing when not in master process\n",
        "    \"\"\"\n",
        "    import builtins as __builtin__\n",
        "\n",
        "    builtin_print = __builtin__.print\n",
        "\n",
        "    def print(*args, **kwargs):\n",
        "        force = kwargs.pop(\"force\", False)\n",
        "        if is_master or force:\n",
        "            builtin_print(*args, **kwargs)\n",
        "\n",
        "    __builtin__.print = print\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def get_rank():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 0\n",
        "    return dist.get_rank()\n",
        "\n",
        "\n",
        "def is_main_process():\n",
        "    return get_rank() == 0\n",
        "\n",
        "\n",
        "def save_on_master(*args, **kwargs):\n",
        "    if is_main_process():\n",
        "        torch.save(*args, **kwargs)\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "        args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
        "    elif \"SLURM_PROCID\" in os.environ:\n",
        "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
        "        args.gpu = args.rank % torch.cuda.device_count()\n",
        "    else:\n",
        "        print(\"Not using distributed mode\")\n",
        "        args.distributed = False\n",
        "        return\n",
        "\n",
        "    args.distributed = True\n",
        "\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "    args.dist_backend = \"nccl\"\n",
        "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
        "    torch.distributed.init_process_group(\n",
        "        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank\n",
        "    )\n",
        "    torch.distributed.barrier()\n",
        "    setup_for_distributed(args.rank == 0)"
      ],
      "metadata": {
        "id": "T5OojTrfUQuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import errno\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        if not is_dist_avail_and_initialized():\n",
        "            return\n",
        "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n",
        "        dist.barrier()\n",
        "        dist.all_reduce(t)\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "\n",
        "\n",
        "def all_gather(data):\n",
        "    \"\"\"\n",
        "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
        "    Args:\n",
        "        data: any picklable object\n",
        "    Returns:\n",
        "        list[data]: list of data gathered from each rank\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size == 1:\n",
        "        return [data]\n",
        "    data_list = [None] * world_size\n",
        "    dist.all_gather_object(data_list, data)\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.inference_mode():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST:\n",
        "            raise\n",
        "\n",
        "\n",
        "def setup_for_distributed(is_master):\n",
        "    \"\"\"\n",
        "    This function disables printing when not in master process\n",
        "    \"\"\"\n",
        "    import builtins as __builtin__\n",
        "\n",
        "    builtin_print = __builtin__.print\n",
        "\n",
        "    def print(*args, **kwargs):\n",
        "        force = kwargs.pop(\"force\", False)\n",
        "        if is_master or force:\n",
        "            builtin_print(*args, **kwargs)\n",
        "\n",
        "    __builtin__.print = print\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def get_rank():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 0\n",
        "    return dist.get_rank()\n",
        "\n",
        "\n",
        "def is_main_process():\n",
        "    return get_rank() == 0\n",
        "\n",
        "\n",
        "def save_on_master(*args, **kwargs):\n",
        "    if is_main_process():\n",
        "        torch.save(*args, **kwargs)\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "        args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
        "    elif \"SLURM_PROCID\" in os.environ:\n",
        "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
        "        args.gpu = args.rank % torch.cuda.device_count()\n",
        "    else:\n",
        "        print(\"Not using distributed mode\")\n",
        "        args.distributed = False\n",
        "        return\n",
        "\n",
        "    args.distributed = True\n",
        "\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "    args.dist_backend = \"nccl\"\n",
        "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
        "    torch.distributed.init_process_group(\n",
        "        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank\n",
        "    )\n",
        "    torch.distributed.barrier()\n",
        "    setup_for_distributed(args.rank == 0)"
      ],
      "metadata": {
        "id": "TMqB97bubYOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, sys\n",
        "\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq,  scaler=None):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
        "    header = f\"Epoch: [{epoch}]\"\n",
        "\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1.0 / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "\n",
        "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
        "        )\n",
        "    \n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        items=targets.keys()\n",
        "        new_targets=[]\n",
        "        \n",
        "        target={}\n",
        "        for item in items:\n",
        "          for i in range(len(images)):\n",
        "            if item==\"boxes\":\n",
        "              new_targets.append(target)\n",
        "            new_targets[i][item]=targets[item][i]\n",
        "          \n",
        "        targets=new_targets\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # reduce losses over all GPUs for logging purposes\n",
        "        loss_dict_reduced = reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        loss_value = losses_reduced.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping training\")\n",
        "            print(loss_dict_reduced)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            scaler.scale(losses).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    return metric_logger\n",
        "\n"
      ],
      "metadata": {
        "id": "jBystax9TQRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "params = [p.to(DEVICE) for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, data_loader_train, DEVICE, epoch, print_freq=1000)\n",
        "    lr_scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "IFhO39WYbZ9A",
        "outputId": "941c0add-a07f-4617-d562-a5af424c7bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-f3b3f9341dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-07885b8135de>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/mobilenetv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 14.76 GiB total capacity; 13.52 GiB already allocated; 19.75 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()#evaluate(model, data_loader_test, DEVICE)\n",
        "with torch.no_grad():\n",
        "  F = transforms.ToTensor()\n",
        "  from PIL import Image\n",
        "  import torchvision.transforms as T\n",
        "  transform = T.ToPILImage()\n",
        "  image=dataset_train.get_image_files()[10]\n",
        "  image=cv2.imread((image))\n",
        "  image=cv2.resize(image, (224, 224))\n",
        "  trans1 = transforms.ToTensor()\n",
        "  print(trans1(image))\n",
        "  print(target)\n",
        "  print(model([trans1(image).to(DEVICE)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaSogaCMS6dG",
        "outputId": "0b521f22-b48f-43c7-ee54-e9a5ace8e336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9333, 0.9373, 0.9412,  ..., 0.9294, 0.9294, 0.9255],\n",
            "         [0.9373, 0.9255, 0.9412,  ..., 0.9255, 0.9333, 0.9294],\n",
            "         [0.9490, 0.9373, 0.9294,  ..., 0.9294, 0.9294, 0.9294],\n",
            "         ...,\n",
            "         [0.5137, 0.2392, 0.2549,  ..., 0.3098, 0.2039, 0.3176],\n",
            "         [0.4275, 0.4941, 0.2353,  ..., 0.2824, 0.1765, 0.1882],\n",
            "         [0.4627, 0.2745, 0.2196,  ..., 0.3255, 0.1647, 0.1882]],\n",
            "\n",
            "        [[0.9333, 0.9294, 0.9333,  ..., 0.9137, 0.9098, 0.9098],\n",
            "         [0.9333, 0.9294, 0.9333,  ..., 0.9098, 0.9059, 0.9059],\n",
            "         [0.9373, 0.9333, 0.9294,  ..., 0.9059, 0.9098, 0.9020],\n",
            "         ...,\n",
            "         [0.7843, 0.5255, 0.5059,  ..., 0.5294, 0.4314, 0.5176],\n",
            "         [0.6667, 0.7216, 0.5647,  ..., 0.4706, 0.4314, 0.4471],\n",
            "         [0.6667, 0.6510, 0.5137,  ..., 0.5490, 0.5647, 0.4431]],\n",
            "\n",
            "        [[0.9333, 0.9294, 0.9333,  ..., 0.8941, 0.8902, 0.8902],\n",
            "         [0.9294, 0.9294, 0.9333,  ..., 0.8902, 0.8863, 0.8863],\n",
            "         [0.9216, 0.9294, 0.9294,  ..., 0.8863, 0.8863, 0.8784],\n",
            "         ...,\n",
            "         [0.6863, 0.5255, 0.5059,  ..., 0.4196, 0.3020, 0.3922],\n",
            "         [0.6863, 0.7255, 0.5451,  ..., 0.3608, 0.2941, 0.3020],\n",
            "         [0.6667, 0.5725, 0.5020,  ..., 0.4392, 0.3804, 0.3333]]])\n",
            "{'boxes': tensor([[0., 0., 1., 1.]]), 'labels': tensor([1]), 'image_id': tensor([4]), 'area': tensor([1.]), 'iscrowd': tensor([0]), 'keypoints': tensor([[[0.6526, 0.4848, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.1718, 0.6596, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.4114, 0.1809, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.9097, 0.6843, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.1043, 0.6478, 1.0000],\n",
            "         [0.6201, 0.1275, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0694, 0.6090, 1.0000],\n",
            "         [0.2107, 0.5983, 1.0000],\n",
            "         [0.3709, 0.0702, 1.0000],\n",
            "         [0.9232, 0.9753, 1.0000],\n",
            "         [0.7859, 0.6320, 1.0000],\n",
            "         [0.2971, 0.3371, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.2670, 0.0815, 1.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]])}\n",
            "[{'boxes': tensor([[2.1047e+02, 0.0000e+00, 2.1873e+02, 4.1818e+00],\n",
            "        [2.1083e+02, 0.0000e+00, 2.1773e+02, 2.1238e+00],\n",
            "        [2.0592e+02, 9.2010e-03, 2.2346e+02, 8.2826e+00],\n",
            "        [2.1353e+02, 0.0000e+00, 2.1708e+02, 3.2909e+00]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.1299, 0.1261, 0.1170, 0.1008], device='cuda:0'), 'keypoints': tensor([[[218.0431,   3.2060,   1.0000],\n",
            "         [214.7393,   3.4848,   1.0000],\n",
            "         [218.5937,   3.7636,   1.0000],\n",
            "         [218.5937,   2.9272,   1.0000],\n",
            "         [213.6381,   3.4848,   1.0000],\n",
            "         [217.2171,   3.2060,   1.0000],\n",
            "         [214.7393,   4.0424,   1.0000],\n",
            "         [214.7393,   3.4848,   1.0000],\n",
            "         [215.0147,   1.2545,   1.0000],\n",
            "         [215.0147,   2.9272,   1.0000],\n",
            "         [218.0431,   1.2545,   1.0000],\n",
            "         [217.4925,   4.0424,   1.0000],\n",
            "         [215.2900,   0.9757,   1.0000],\n",
            "         [217.4925,   3.4848,   1.0000],\n",
            "         [217.2171,   2.9272,   1.0000],\n",
            "         [214.4640,   2.9272,   1.0000],\n",
            "         [218.0431,   2.6485,   1.0000],\n",
            "         [218.5937,   3.2060,   1.0000],\n",
            "         [218.0431,   1.2545,   1.0000],\n",
            "         [218.5937,   1.2545,   1.0000],\n",
            "         [216.9418,   2.3697,   1.0000],\n",
            "         [215.0147,   3.2060,   1.0000],\n",
            "         [218.0431,   0.9757,   1.0000],\n",
            "         [214.7393,   3.7636,   1.0000],\n",
            "         [217.4925,   3.2060,   1.0000],\n",
            "         [217.2171,   1.5333,   1.0000],\n",
            "         [216.9418,   1.5333,   1.0000],\n",
            "         [215.0147,   0.9757,   1.0000],\n",
            "         [215.0147,   4.0424,   1.0000],\n",
            "         [218.0431,   2.9272,   1.0000]],\n",
            "\n",
            "        [[215.3852,   1.7256,   1.0000],\n",
            "         [215.6610,   1.7256,   1.0000],\n",
            "         [217.5915,   1.7256,   1.0000],\n",
            "         [217.0399,   1.7256,   1.0000],\n",
            "         [215.6610,   1.7256,   1.0000],\n",
            "         [217.0399,   1.7256,   1.0000],\n",
            "         [215.3852,   1.7256,   1.0000],\n",
            "         [216.7642,   1.7256,   1.0000],\n",
            "         [215.6610,   0.6637,   1.0000],\n",
            "         [215.6610,   1.4601,   1.0000],\n",
            "         [216.7642,   0.3982,   1.0000],\n",
            "         [217.3157,   1.7256,   1.0000],\n",
            "         [215.9368,   0.6637,   1.0000],\n",
            "         [217.5915,   1.7256,   1.0000],\n",
            "         [215.6610,   1.7256,   1.0000],\n",
            "         [215.6610,   1.4601,   1.0000],\n",
            "         [217.0399,   1.1947,   1.0000],\n",
            "         [213.1789,   1.7256,   1.0000],\n",
            "         [215.9368,   1.1947,   1.0000],\n",
            "         [216.4884,   1.1947,   1.0000],\n",
            "         [217.5915,   1.7256,   1.0000],\n",
            "         [216.2126,   1.4601,   1.0000],\n",
            "         [217.0399,   0.3982,   1.0000],\n",
            "         [215.3852,   1.7256,   1.0000],\n",
            "         [213.1789,   1.7256,   1.0000],\n",
            "         [216.4884,   1.1947,   1.0000],\n",
            "         [216.2126,   0.6637,   1.0000],\n",
            "         [215.6610,   0.6637,   1.0000],\n",
            "         [217.5915,   1.9911,   1.0000],\n",
            "         [217.0399,   1.4601,   1.0000]],\n",
            "\n",
            "        [[221.9288,   4.5596,   1.0000],\n",
            "         [218.0317,   6.2142,   1.0000],\n",
            "         [223.3207,   8.1447,   1.0000],\n",
            "         [223.3207,   4.5596,   1.0000],\n",
            "         [221.3721,   4.2838,   1.0000],\n",
            "         [220.5370,   7.5931,   1.0000],\n",
            "         [217.4749,   7.8689,   1.0000],\n",
            "         [220.5370,   7.3173,   1.0000],\n",
            "         [220.5370,   4.0080,   1.0000],\n",
            "         [218.0317,   5.9384,   1.0000],\n",
            "         [220.5370,   2.3533,   1.0000],\n",
            "         [220.8154,   7.8689,   1.0000],\n",
            "         [219.4235,   2.9049,   1.0000],\n",
            "         [220.5370,   7.0416,   1.0000],\n",
            "         [222.4856,   4.5596,   1.0000],\n",
            "         [219.4235,   5.6627,   1.0000],\n",
            "         [220.5370,   4.8353,   1.0000],\n",
            "         [221.3721,   4.5596,   1.0000],\n",
            "         [221.9288,   4.2838,   1.0000],\n",
            "         [223.3207,   4.2838,   1.0000],\n",
            "         [223.3207,   4.2838,   1.0000],\n",
            "         [219.4235,   6.2142,   1.0000],\n",
            "         [221.9288,   1.8018,   1.0000],\n",
            "         [217.4749,   7.3173,   1.0000],\n",
            "         [220.5370,   6.4900,   1.0000],\n",
            "         [219.9803,   3.1807,   1.0000],\n",
            "         [219.4235,   3.4564,   1.0000],\n",
            "         [219.4235,   1.8018,   1.0000],\n",
            "         [221.9288,   8.1447,   1.0000],\n",
            "         [221.9288,   4.5596,   1.0000]],\n",
            "\n",
            "        [[216.1269,   2.6053,   1.0000],\n",
            "         [214.7597,   2.6053,   1.0000],\n",
            "         [216.9473,   2.8795,   1.0000],\n",
            "         [216.1269,   2.6053,   1.0000],\n",
            "         [216.6738,   2.8795,   1.0000],\n",
            "         [216.6738,   2.6053,   1.0000],\n",
            "         [216.1269,   2.8795,   1.0000],\n",
            "         [216.4004,   2.8795,   1.0000],\n",
            "         [213.6659,   1.2341,   1.0000],\n",
            "         [215.0331,   2.3310,   1.0000],\n",
            "         [214.7597,   0.6856,   1.0000],\n",
            "         [216.6738,   2.8795,   1.0000],\n",
            "         [216.1269,   1.2341,   1.0000],\n",
            "         [216.9473,   2.8795,   1.0000],\n",
            "         [216.4004,   2.0568,   1.0000],\n",
            "         [216.1269,   2.6053,   1.0000],\n",
            "         [216.1269,   0.9598,   1.0000],\n",
            "         [216.9473,   2.0568,   1.0000],\n",
            "         [216.1269,   2.0568,   1.0000],\n",
            "         [216.4004,   2.0568,   1.0000],\n",
            "         [216.4004,   2.0568,   1.0000],\n",
            "         [216.4004,   2.0568,   1.0000],\n",
            "         [216.6738,   0.4114,   1.0000],\n",
            "         [216.1269,   2.8795,   1.0000],\n",
            "         [216.1269,   2.6053,   1.0000],\n",
            "         [216.4004,   1.2341,   1.0000],\n",
            "         [216.4004,   1.2341,   1.0000],\n",
            "         [216.1269,   0.4114,   1.0000],\n",
            "         [214.7597,   3.1537,   1.0000],\n",
            "         [216.4004,   2.6053,   1.0000]]], device='cuda:0'), 'keypoints_scores': tensor([[21.7595, 11.0924,  5.1326, 15.4062, 15.4965, 12.0393,  7.1951,  4.2362,\n",
            "          8.3640, 18.4889, 18.9119,  6.8455, 19.1015, 14.8663, 17.7379, 10.7233,\n",
            "         14.1115, 18.5404, 18.8001,  4.0397, 15.1139, 24.4926, 14.3823, 10.7941,\n",
            "         14.9121, 18.5905, 17.4371, 19.0055,  6.7938, 16.8610],\n",
            "        [22.2917,  9.0762,  2.8328, 15.6581, 15.1320, 11.3244,  5.6727,  4.4907,\n",
            "          8.3540, 18.8241, 16.9145,  4.9501, 18.9195, 12.4141, 18.7925, 11.2066,\n",
            "         15.0362, 18.4188, 17.3049,  3.3258, 15.1538, 24.3418, 12.4667,  9.5150,\n",
            "         13.6594, 18.6362, 17.0296, 18.0133,  5.7342, 15.8769],\n",
            "        [21.7964,  9.7121,  7.5315, 15.1286, 15.7836, 11.5030,  7.6591,  6.8192,\n",
            "          9.2492, 18.1649, 18.4343,  7.3466, 19.9729, 15.3239, 17.5717, 11.7031,\n",
            "         15.9035, 19.1831, 19.1851,  4.2441, 16.6781, 25.1552, 13.9764, 11.0970,\n",
            "         15.3028, 19.7641, 17.9843, 18.5015, 10.7761, 17.6469],\n",
            "        [22.5071,  6.7390,  4.3533, 14.3707, 13.5638,  9.7771,  8.1550,  6.8435,\n",
            "          7.4631, 17.5709, 16.4882,  7.6113, 19.7667, 11.2547, 18.2674, 10.1451,\n",
            "         13.7226, 18.3644, 17.8467,  4.2165, 15.2221, 21.7915, 11.6062, 10.8874,\n",
            "         14.3563, 19.8439, 17.2397, 18.7341,  4.5023, 11.6810]],\n",
            "       device='cuda:0')}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  image, target=dataset_train.__getitem__(4)\n",
        "  print(model([image.to(DEVICE)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJtlgnOClkxG",
        "outputId": "cbd7da87-19e7-4976-bda9-b3cf36997e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'boxes': tensor([[4.4424e-03, 1.0510e-02, 2.3376e+00, 1.5848e+00],\n",
            "        [8.9172e-03, 3.1159e-02, 4.6922e+00, 4.6987e+00],\n",
            "        [1.4326e-02, 5.5191e-02, 7.5386e+00, 8.3226e+00],\n",
            "        [1.8049e-02, 3.4192e-02, 1.4075e+01, 6.1018e+00],\n",
            "        [0.0000e+00, 1.5283e+00, 1.1542e+01, 1.5469e+01],\n",
            "        [0.0000e+00, 5.4665e-02, 2.2775e+01, 1.0845e+01],\n",
            "        [3.3766e+00, 4.8904e-02, 1.5151e+01, 1.4088e+01],\n",
            "        [0.0000e+00, 4.0022e+00, 4.6131e+00, 1.2583e+01],\n",
            "        [4.0461e+00, 2.4690e-02, 1.2914e+01, 4.1225e+00],\n",
            "        [7.5304e+00, 8.3052e-03, 1.1823e+01, 1.1064e+00],\n",
            "        [8.6557e+00, 1.8071e-02, 1.0646e+01, 2.6565e+00],\n",
            "        [0.0000e+00, 7.4670e+00, 9.1397e-01, 1.1079e+01],\n",
            "        [5.0277e+00, 3.8577e+00, 1.4059e+01, 1.2589e+01],\n",
            "        [0.0000e+00, 9.7097e-02, 6.1209e+00, 2.1062e+01],\n",
            "        [0.0000e+00, 8.7001e+00, 1.7206e+00, 1.0309e+01]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.1409, 0.1409, 0.1409, 0.1296, 0.1197, 0.1081, 0.1075, 0.1063, 0.1060,\n",
            "        0.1032, 0.0995, 0.0928, 0.0792, 0.0767, 0.0540], device='cuda:0'), 'keypoints': tensor([[[ 1.4303,  0.6665,  1.0000],\n",
            "         [ 1.6895,  0.6665,  1.0000],\n",
            "         [ 1.9488,  1.1913,  1.0000],\n",
            "         ...,\n",
            "         [ 0.6526,  0.4041,  1.0000],\n",
            "         [ 1.4303,  0.6665,  1.0000],\n",
            "         [ 1.9488,  0.6665,  1.0000]],\n",
            "\n",
            "        [[ 2.6260,  1.8158,  1.0000],\n",
            "         [ 2.9015,  3.1886,  1.0000],\n",
            "         [ 4.0035,  2.0903,  1.0000],\n",
            "         ...,\n",
            "         [ 1.2486,  0.4430,  1.0000],\n",
            "         [ 2.6260,  2.6395,  1.0000],\n",
            "         [ 3.7280,  2.0903,  1.0000]],\n",
            "\n",
            "        [[ 4.3338,  3.2244,  1.0000],\n",
            "         [ 5.7272,  5.7046,  1.0000],\n",
            "         [ 6.5632,  3.2244,  1.0000],\n",
            "         ...,\n",
            "         [ 2.1044,  1.8465,  1.0000],\n",
            "         [ 4.6125,  4.0511,  1.0000],\n",
            "         [ 6.0059,  3.7755,  1.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 8.7225,  7.2684,  1.0000],\n",
            "         [12.0067,  9.9970,  1.0000],\n",
            "         [12.0067, 10.5427,  1.0000],\n",
            "         ...,\n",
            "         [ 6.8067,  4.8127,  1.0000],\n",
            "         [ 8.7225,  8.0870,  1.0000],\n",
            "         [12.2803,  8.6327,  1.0000]],\n",
            "\n",
            "        [[ 2.9214,  8.0639,  1.0000],\n",
            "         [ 4.3125, 14.4933,  1.0000],\n",
            "         [ 5.1472, 16.1705,  1.0000],\n",
            "         ...,\n",
            "         [ 1.2520,  2.1936,  1.0000],\n",
            "         [ 2.9214,  8.6230,  1.0000],\n",
            "         [ 4.8689,  9.4616,  1.0000]],\n",
            "\n",
            "        [[ 0.6145,  9.3707,  1.0000],\n",
            "         [ 0.8603,  9.9071,  1.0000],\n",
            "         [ 1.5977,  9.9071,  1.0000],\n",
            "         ...,\n",
            "         [ 0.3687,  9.1024,  1.0000],\n",
            "         [ 0.8603,  9.9071,  1.0000],\n",
            "         [ 1.3519,  9.6389,  1.0000]]], device='cuda:0'), 'keypoints_scores': tensor([[16.2742,  5.4449,  3.6029, 10.2957, 13.1399,  5.6334,  5.3538,  4.7783,\n",
            "          4.1796, 15.3024, 14.5257,  4.0884, 12.9641,  9.0516, 10.0203,  6.2949,\n",
            "          7.3458, 10.2842, 11.6342,  3.6752, 13.0820, 16.7282, 12.3869,  6.6644,\n",
            "          9.1323, 13.3202, 10.7482, 11.9356,  4.2724,  5.8914],\n",
            "        [16.9820,  6.0862,  3.5751, 10.9407, 14.1094,  6.9578,  7.6197,  4.5764,\n",
            "          5.6917, 18.0219, 15.5566,  4.2112, 14.2415,  8.1762, 10.6547,  8.0572,\n",
            "          9.3422, 13.8410, 11.3974,  4.5950, 10.4621, 15.1800, 13.6481,  8.7828,\n",
            "         11.8492, 15.2916, 14.3617, 12.5835,  4.1758,  8.1360],\n",
            "        [16.5275,  6.6683,  4.1849, 10.4639, 13.7780,  7.0484,  7.3974,  5.1115,\n",
            "          4.9761, 16.7045, 14.5700,  4.1663, 13.9893,  9.4121, 11.2250,  7.5783,\n",
            "         10.2961, 13.0618, 12.6456,  4.7067, 13.5230, 17.1736, 13.1567,  8.4008,\n",
            "         11.8610, 16.3380, 14.2895, 12.4018,  4.6054,  8.2528],\n",
            "        [19.3743,  7.7618,  5.1404, 12.6736, 15.8901,  8.7460,  8.4606,  6.3916,\n",
            "          6.4076, 21.1847, 17.5811,  6.5626, 16.2458, 10.8787, 12.8306,  9.1028,\n",
            "         11.9049, 14.6856, 16.2196,  5.5546, 15.5817, 20.8550, 15.5588,  9.8278,\n",
            "         14.4532, 19.5606, 16.9852, 14.3527,  6.6140,  9.4854],\n",
            "        [13.9648,  5.6318,  4.1450,  8.1253, 11.1561,  5.9420,  6.6190,  4.5117,\n",
            "          4.5743, 15.5400, 13.2713,  4.2766, 12.6045,  7.7017,  8.9084,  5.5703,\n",
            "          8.3035, 10.2797, 11.2043,  3.8841, 10.0470, 14.2373, 13.1239,  6.8674,\n",
            "          9.6713, 12.8423, 11.5270, 11.5589,  4.8598,  6.2535],\n",
            "        [18.6775,  7.1015,  4.9113, 12.0237, 16.7418,  8.2655,  9.5913,  6.1321,\n",
            "          6.8317, 22.2076, 16.7993,  5.6895, 17.1796, 10.5514, 12.7759,  9.0294,\n",
            "         11.9183, 15.2035, 15.4895,  5.2814, 14.3855, 19.9008, 14.5656,  9.8671,\n",
            "         13.6659, 18.9031, 17.6436, 15.3191,  5.7798,  7.9915],\n",
            "        [18.2096,  6.6900,  4.9398, 11.5842, 15.1743,  6.9920,  8.7592,  5.3527,\n",
            "          6.5029, 20.0127, 16.6806,  5.9491, 16.0077, 10.2770, 11.9213,  7.6092,\n",
            "         11.2029, 13.6101, 15.1519,  5.3595, 14.0743, 19.3697, 15.2492,  9.4105,\n",
            "         12.9952, 17.2898, 16.5360, 14.7699,  6.2547,  7.4721],\n",
            "        [10.5618,  3.9321,  3.3179,  6.3324,  8.3006,  4.9762,  4.5204,  3.1773,\n",
            "          3.5296, 11.3494, 10.4321,  3.2052,  9.3133,  5.6552,  6.6842,  4.6724,\n",
            "          6.6092,  8.1487,  8.5718,  3.0095,  8.4994, 11.3296,  9.3022,  5.2545,\n",
            "          7.1774,  9.5035,  9.5368,  8.4676,  3.5364,  5.4140],\n",
            "        [19.0640,  8.9892,  5.8579, 12.5976, 16.4921,  9.7131,  8.8655,  6.3160,\n",
            "          7.0598, 22.6655, 17.5342,  7.5466, 16.8936, 11.3505, 13.0378,  9.0634,\n",
            "         12.3245, 15.2767, 17.4202,  6.2741, 13.3750, 19.9046, 15.2923, 11.0739,\n",
            "         14.6625, 21.2655, 18.1659, 15.5560,  6.1937,  9.6249],\n",
            "        [19.5818,  7.4456,  3.9017, 13.1352, 15.8235,  8.7322,  8.5275,  4.3948,\n",
            "          4.3107, 22.9704, 14.6571,  6.6382, 12.9230, 10.0865, 12.0898,  9.0541,\n",
            "         10.4176, 15.5414, 14.8269,  5.6418, 12.9516, 18.2423, 16.2045,  7.3381,\n",
            "         14.3493, 19.7299, 18.8973, 14.5972,  5.1142,  6.5805],\n",
            "        [18.9287,  7.8054,  4.1400, 12.1194, 16.4904,  7.5605,  9.5026,  5.8701,\n",
            "          5.2887, 20.9241, 16.5002,  5.1627, 15.7120, 10.7058, 13.3709,  9.1871,\n",
            "         10.2525, 15.3040, 14.7692,  4.5007, 14.2957, 20.4807, 14.5639, 10.1250,\n",
            "         14.4118, 18.9743, 16.1701, 14.9228,  5.1387,  8.4829],\n",
            "        [ 6.5296,  3.5950,  2.9443,  4.8387,  5.4038,  3.4071,  3.9630,  3.3422,\n",
            "          2.1336,  6.9572,  7.8589,  3.1607,  5.9926,  5.2233,  4.8001,  3.0575,\n",
            "          3.9704,  4.9100,  5.0066,  1.6709,  5.4983,  7.0595,  6.1492,  3.6744,\n",
            "          5.8553,  6.5953,  6.2467,  5.2081,  2.9500,  3.7068],\n",
            "        [13.1438,  5.8782,  4.2115,  8.1260, 11.0852,  6.7154,  6.3432,  4.8814,\n",
            "          5.7777, 13.0770, 13.1022,  4.2243, 12.5033,  7.2541,  8.4253,  5.4898,\n",
            "          8.7270,  9.8909, 11.4393,  4.1946,  9.7666, 13.1782, 11.8214,  6.7835,\n",
            "          8.7665, 12.8021, 12.8463, 11.8588,  4.5581,  6.7150],\n",
            "        [11.6219,  5.4614,  4.0594,  6.8621,  9.3563,  5.8340,  5.6461,  4.4152,\n",
            "          4.3275, 12.9651, 11.1811,  4.0697, 10.7701,  6.4621,  7.9557,  4.8520,\n",
            "          7.1858,  8.1978,  9.0016,  3.1117,  8.5058, 11.4287, 11.2030,  5.8435,\n",
            "          7.9483, 11.1790, 10.4854, 10.2691,  4.3248,  5.4464],\n",
            "        [ 6.2916,  2.1898,  2.1315,  4.1257,  5.5123,  2.8342,  3.7072,  3.6268,\n",
            "          1.6193,  5.2841,  5.7992,  1.4245,  5.2375,  5.2912,  4.2147,  3.0543,\n",
            "          2.6684,  5.0915,  4.5505,  0.7939,  5.0167,  5.7432,  4.8383,  3.9540,\n",
            "          3.9831,  5.5322,  4.9337,  5.3872,  1.5027,  3.9738]],\n",
            "       device='cuda:0')}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [torch.rand(3, 300, 400).to(DEVICE), torch.rand(3, 500, 400).to(DEVICE)]\n",
        "predictions = model(x)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "bM0cd7FjT7Uq",
        "outputId": "449ed1c5-2500-4da4-edcd-9f9dd8666b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-ead6e8fd60e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mkeypoint_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeypoint_roi_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint_proposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mkeypoint_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeypoint_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoint_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mkeypoint_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeypoint_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoint_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mloss_keypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/detection/keypoint_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkps_score_lowres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         return torch.nn.functional.interpolate(\n\u001b[1;32m    306\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecompute_scale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    954\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             output_padding, self.groups, self.dilation)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 14.76 GiB total capacity; 13.47 GiB already allocated; 14.75 MiB free; 13.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, data_loader_test, device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "o_PeNtjaUVQp",
        "outputId": "448b426c-edfc-48f7-c4d8-c4ccabfbf31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-497a5062b234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-2fc89989439e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0miou_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_iou_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcoco_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCocoEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-f8fa0d01d830>\u001b[0m in \u001b[0;36mget_coco_api_from_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCocoDetection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_coco_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'convert_to_coco_api' is not defined"
          ]
        }
      ]
    }
  ]
}